{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T14:45:07.532256Z",
     "start_time": "2020-06-07T14:45:01.783758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Necessary Imports\n",
    "from tqdm import tqdm_notebook\n",
    "import pathlib\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.layers as layers\n",
    "from pathlib import Path\n",
    "import time \n",
    "import subprocess\n",
    "from shutil import copyfile\n",
    "\n",
    "    \n",
    "# Custom Metric to load the models without problems\n",
    "import keras.backend as K\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "def kullback_leibler_divergence_test_2(y_true, y_pred):\n",
    "\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1)\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
    "    return K.sum(y_true * abs(K.log(y_true /  y_pred)), axis=-1)\n",
    "\n",
    "custom_metr = custom_objects={\n",
    "        \"kullback_leibler_divergence_test_2\":kullback_leibler_divergence_test_2,\n",
    "        \"dice_coef\": dice_coef}\n",
    "\n",
    "    \n",
    "# Define The Path of the Test Set\n",
    "# Make a function to load the Inputs from the Files as np.array to predict from it\n",
    "def create_instance(TEST_SET_PATH):\n",
    "    instances = []\n",
    "    input_path =os.path.join(TEST_SET_PATH,\"Input\")\n",
    "    input_names = os.listdir(input_path)\n",
    "    for i in input_names:\n",
    "        instance= np.load(os.path.join(input_path,i),allow_pickle = True)\n",
    "        instances.append(instance)\n",
    "    return np.array(instances),input_names\n",
    "def load_models(IDs,TRIALS_ROOT):\n",
    "    loaded_models = []\n",
    "    for ID in IDs:\n",
    "        model_path  =os.path.join(TRIALS_ROOT,ID,str(ID+\".h5\"))\n",
    "        loaded_model = tf.keras.models.load_model(model_path,custom_metr)\n",
    "        loaded_models.append(loaded_model)\n",
    "    return loaded_models\n",
    "\n",
    "def load_model(ID, MODEL_ROOT):\n",
    "    model_path  =os.path.join(MODEL_ROOT,ID,str(ID+\".h5\"))\n",
    "    loaded_model = tf.keras.models.load_model(model_path,custom_metr)\n",
    "    return loaded_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T16:12:13.610181Z",
     "start_time": "2020-06-03T16:12:13.586250Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the files as a list of the individual lines of the files\n",
    "def line_by_line(path_):\n",
    "  as_list=[]\n",
    "  f = open(path_, 'r')\n",
    "  for line in f:      \n",
    "      as_list.append(line.strip())\n",
    "  return as_list\n",
    "\n",
    "\n",
    "# OUT DATA\n",
    "# Get the number of nodes in the Structure\n",
    "def get_num_nodes(list_):\n",
    "  numnodes_i= [i for i, s in enumerate(list_) if 'Total # of Grids (Structural)' in s]\n",
    "  step1=list_[numnodes_i[0]].split()\n",
    "  num_nodes=(int(step1[-1]))\n",
    "  return num_nodes\n",
    "\n",
    "# Get the number of elements in the structure\n",
    "def get_num_elements(list_):\n",
    "  numelements_i= [i for i, s in enumerate(list_) if 'Total # of Elements' in s]\n",
    "  step1=list_[numelements_i[0]].split()\n",
    "  num_elements=(int(step1[-1]))\n",
    "  return num_elements\n",
    "\n",
    "\n",
    "# Input Deck Data\n",
    "# DON'T FORGET!: We start indexing at 0, so Node 132 for example is node_pos[131]\n",
    "\n",
    "# Extracting the volume fraction\n",
    "def get_vol_frac(list_):\n",
    "  volfrac_i= [i for i, s in enumerate(list_) if 'DCONSTR  ' in s]\n",
    "  volfrac_i= int(volfrac_i[0])\n",
    "  step1=list_[volfrac_i].split()\n",
    "  volfrac=(float(step1[-1]))\n",
    "  return volfrac\n",
    "\n",
    "# We get the position of nodes, in this case the element size is 2.5\n",
    "def get_nodes_pos(list_,num_nodes):\n",
    "# Defining the area, in which the nodes positions are saved (grid_area)\n",
    "  grid_start_i= [i for i, s in enumerate(list_) if '  GRID Data' in s]\n",
    "  pos= []\n",
    "  grid_start_i=int(grid_start_i[0])+2\n",
    "  grid_end_i = int(grid_start_i+int(num_nodes))\n",
    "  grid_area= list_[grid_start_i:grid_end_i]\n",
    "# Now we are accessing each line in the grid area and getting the nodes positions, \n",
    "# those have the string length of 8 characters, thats why we are accessing them through indexes\n",
    "# Also there are some cases in which the position is not 0, but some very small number like:\n",
    "# 3.553-15120, this is why we check also for \"-\" in the position\n",
    "  for i,s in enumerate(grid_area):\n",
    "  \n",
    "    x_pos= s[24:32]\n",
    "    y_pos= s[32:40]\n",
    "    if \"-\" in x_pos:\n",
    "      x_pos= 0\n",
    "    else:\n",
    "      x_pos= int(float(x_pos)/2.5)\n",
    "    if \"-\" in y_pos:\n",
    "      y_pos= 0\n",
    "    else:\n",
    "      y_pos= int(float(y_pos)/2.5)   \n",
    "    pos.append([x_pos,y_pos])  \n",
    "  return pos\n",
    "\n",
    "def get_elements_pos(list_,num_elements,nodes_pos):\n",
    "# Our Elements pos is equal to the node position of the lower left node\n",
    "# Since we read in the Nodes mentioned in the Input deck, we have to substract 1 from\n",
    "# the Node defined in the input deck, since we start indexing at 0\n",
    "# Define the area containing the elements\n",
    "  ele_start_i= [i for i, s in enumerate(list_) if '  CQUAD4 Elements' in s]\n",
    "  pos= []\n",
    "  ele_start_i=int(ele_start_i[0])+2\n",
    "  ele_end_i = int(ele_start_i+int(num_elements))\n",
    "  ele_area= list_[ele_start_i:ele_end_i]\n",
    "  for i,s in enumerate(ele_area):\n",
    "# Split the Nodes, which define the Element\n",
    "    s= s.split()\n",
    "# We only need the lower left node, which is the second node defined in the QUAD\n",
    "# We substract -1 to get the right node element in our vector, since indexing\n",
    "# This approach didnt work out, and is therefore commented out\n",
    "    # node_2 = int(s[4])-1\n",
    "    # node_2_pos=nodes_pos[node_2]\n",
    "    # x_pos=node_2_pos[0]\n",
    "    # y_pos=node_2_pos[1]\n",
    "    in_1=int(s[3])-1\n",
    "    in_2=int(s[4])-1\n",
    "    in_3=int(s[5])-1\n",
    "    in_4=int(s[6])-1\n",
    "# The Approach with the second node doesnt work for some reason\n",
    "# Thats why we just take the minimal entry for the lower left node\n",
    "    min_pos= (min(nodes_pos[in_1],nodes_pos[in_2],nodes_pos[in_3],nodes_pos[in_4]))\n",
    "    x_pos=min_pos[0]\n",
    "    y_pos=min_pos[1]\n",
    "    pos.append([x_pos,y_pos])\n",
    "    \n",
    "  return pos\n",
    "\n",
    "# Takes the nodes positions and volfrac and makes a volfrac and node matrix\n",
    "# The Volfrac matrix is just a matrix filled with the volume fraction\n",
    "# The Node matrix is a matrix containing the sorted nodes positions\n",
    "def get_nodes_volfrac_matrix(nodes_pos,volfrac):\n",
    "# Shape doesn't care about indexing, since the 0th entry counts as well\n",
    "  max_x =max(i[0] for i in nodes_pos)+1\n",
    "  max_y =max(i[1] for i in nodes_pos)+1\n",
    "  node_matrix= np.zeros((max_x,max_y))\n",
    "  for i,s in enumerate(nodes_pos):\n",
    "    i+=1\n",
    "    x_=s[0]\n",
    "    y_=s[1]\n",
    "    node_matrix[x_,y_]=i\n",
    "\n",
    "  volfrac_matrix=np.full((max_x-1,max_y-1),volfrac)\n",
    "  return node_matrix.astype(int), volfrac_matrix.astype(float),max_x,max_y\n",
    "\n",
    "# Same with the element matrix\n",
    "def get_elements_matrix(elements_pos):\n",
    "  max_x =max(i[0] for i in elements_pos)+1\n",
    "  max_y =max(i[1] for i in elements_pos)+1 \n",
    "  elements_matrix= np.zeros((max_x,max_y))\n",
    "  for i,s in enumerate(elements_pos):  \n",
    "    i+=1\n",
    "    x_=s[0]\n",
    "    y_=s[1]\n",
    "    elements_matrix[x_,y_]=i\n",
    "  return elements_matrix.astype(int),max_x,max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T16:12:18.020286Z",
     "start_time": "2020-06-03T16:12:18.012346Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_el_matrix_from_path(folder_name,DATA_PATH):\n",
    "  final=[]\n",
    "  DATA_PATH = os.path.join(DATA_PATH, folder_name)\n",
    "  paths=[]\n",
    "  path_names= ['inputDeck.fem','inputDeck.disp','inputDeck.dens', 'inputDeck.out','inputDeck.strs','change.fem']\n",
    "  for path_name in path_names:\n",
    "    path_ = os.path.join(DATA_PATH, path_name)\n",
    "    paths.append(path_)\n",
    "  data_0 = []  \n",
    "  for path_ in paths:\n",
    "    data_read= line_by_line(path_)\n",
    "    data_0.append(data_read)\n",
    "# Out\n",
    "  num_nodes = get_num_nodes(data_0[3])\n",
    "  num_elements = get_num_elements(data_0[3])\n",
    "# fem\n",
    "  volfrac = get_vol_frac(data_0[5])\n",
    "  nodes_pos = get_nodes_pos(data_0[0],num_nodes)\n",
    "  elements_pos = get_elements_pos(data_0[0],num_elements,nodes_pos)\n",
    "  elements_matrix, x_shape_elements,y_shape_elements = get_elements_matrix(elements_pos)\n",
    "  nodes_matrix,volfrac_matrix,x_shape_nodes,y_shape_nodes = get_nodes_volfrac_matrix(nodes_pos,volfrac)\n",
    "  return (elements_matrix)\n",
    "    \n",
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T16:46:33.431445Z",
     "start_time": "2020-06-03T16:46:33.418517Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function reads in and copies necessary data. It modifies data and uses the model to predict \n",
    "# after the prediction is made a new inputDeck is generated\n",
    "def create_prediction_txt(model,DATA_PATH_RAW,SPLIT_DATA_PATH, model_id\n",
    "                      ,SAVE_ROOT,converter_path):\n",
    "    test_instances,test_names = create_instance(SPLIT_DATA_PATH)\n",
    "    pred_times = []\n",
    "    for i,s in enumerate(test_instances):\n",
    "# Loadcase names not containing the .npy ending\n",
    "        no_npy = test_names[i][:-4]\n",
    "        print(no_npy)\n",
    "# Creates the folder to save the data to\n",
    "        txt_DATA_FOLDER = os.path.join(SAVE_ROOT,no_npy)\n",
    "        os.makedirs(txt_DATA_FOLDER,exist_ok=True)\n",
    "        txt_dir = txt_DATA_FOLDER\n",
    "# Creates the folders for the input decks with and without penalty\n",
    "        with_p = os.path.join(txt_dir,\"WithP\")\n",
    "        without_p =  os.path.join(txt_dir,\"WithoutP\")\n",
    "        os.makedirs(with_p,exist_ok=True)\n",
    "        os.makedirs(without_p,exist_ok=True)\n",
    "# Locates the folder with the raw data and the data required to copy      \n",
    "        test_set_folder = os.path.join(DATA_PATH_RAW, no_npy)\n",
    "        input_deck = \"inputDeck.fem\"\n",
    "        change_ = \"change.fem\"\n",
    "# Copies the inputDeck.fem, change.fem and the .exe to generate the newInputDeck\n",
    "        copyfile(test_set_folder+\"\\\\\"+input_deck, txt_dir + \"\\\\\" + input_deck)\n",
    "        copyfile(test_set_folder+\"\\\\\"+change_, txt_dir + \"\\\\\" + change_)\n",
    "        copyfile(converter_path+\"\\\\\"+\"Avdalim_OptiStruct.exe\", txt_dir + \"\\\\\" + \"Avdalim_OptiStruct.exe\")\n",
    "        element_matrix = get_el_matrix_from_path(no_npy,DATA_PATH_RAW)\n",
    "# Creates the txt title based on the model id and the Loadcase\n",
    "        txt_title = str(str(no_npy)+\"Model\"+str(model_id) + \".txt\")\n",
    "# Predicts and measures the time needed for the prediction\n",
    "        t = time.time()\n",
    "        prediction = model.predict(np.array([s]))\n",
    "        elapsed = time.time() - t\n",
    "        print(\"Elapsed prediction time: \", elapsed)\n",
    "        pred_times.append(float(elapsed))\n",
    "# Reshapes, flattens and zips the matrices of the structure densities and the elements IDs\n",
    "# this means that each element receives a density \n",
    "        get_shape = np.shape(prediction[0][0])\n",
    "        resh = np.reshape(prediction,  (get_shape))\n",
    "        flat_pred = np.ndarray.flatten(resh)\n",
    "# Rotate element matrix to cartesian\n",
    "        element_matrix = np.rot90(element_matrix)\n",
    "        flat_ele = np.ndarray.flatten(element_matrix)\n",
    "        merged = np.array(list(zip(flat_ele,flat_pred)))\n",
    "        txt_path = os.path.join(txt_dir, txt_title)\n",
    "# Sorts the element densities by the Element ID\n",
    "        sort_ = sorted(merged, key=lambda x: x[0])\n",
    "# Saves the txt\n",
    "        np.savetxt(txt_path, sort_, fmt='%5s')\n",
    "        as_array = np.array([[txt_title],[input_deck]])\n",
    "# creates config file for the converter .exe\n",
    "        config_path = os.path.join(txt_dir, \"config.txt\")\n",
    "        np.savetxt(config_path, as_array, fmt='%5s')    \n",
    "        os.chdir(txt_dir)\n",
    "# Runs the converter\n",
    "        p = subprocess.Popen(\"Avdalim_OptiStruct.exe\")\n",
    "    print(\"Total sum of prediction time: \", sum(pred_times), \"average time per instance: \", \n",
    "         sum(pred_times) / len(pred_times))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
