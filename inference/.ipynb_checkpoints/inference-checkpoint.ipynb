{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:49:18.887733Z",
     "start_time": "2020-06-07T13:49:13.387893Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avdalim\\Anaconda3\\envs\\Thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Avdalim\\Anaconda3\\envs\\Thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Avdalim\\Anaconda3\\envs\\Thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Avdalim\\Anaconda3\\envs\\Thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Avdalim\\Anaconda3\\envs\\Thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Avdalim\\Anaconda3\\envs\\Thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from data_modification_inf.ipynb\n",
      "Importing Jupyter notebook from split_data_inf.ipynb\n",
      "Importing Jupyter notebook from create_output_txt.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.layers as layers\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import nbimporter\n",
    "import data_modification_inf as Modify\n",
    "import split_data_inf as Split\n",
    "import create_output_txt as Outtxt\n",
    "import subprocess\n",
    "from shutil import copyfile\n",
    "import time\n",
    "# Loads in custom metrics\n",
    "import keras.backend as K\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "def kullback_leibler_divergence_test_2(y_true, y_pred):\n",
    "\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1)\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
    "    return K.sum(y_true * abs(K.log(y_true /  y_pred)), axis=-1)\n",
    "\n",
    "custom_metr = custom_objects={\n",
    "        \"kullback_leibler_divergence_test_2\":kullback_leibler_divergence_test_2,\n",
    "        \"dice_coef\": dice_coef}\n",
    "def load_model(ID, MODEL_ROOT):\n",
    "    model_path  =os.path.join(MODEL_ROOT,str(ID+\".h5\"))\n",
    "    loaded_model = tf.keras.models.load_model(model_path,custom_metr)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:49:19.369623Z",
     "start_time": "2020-06-07T13:49:18.888457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enter the Inference Folder Path\n",
    "INFERENCE_FOLDER_PATH = \"\"\n",
    "# Enter the ID of the model located in the utils subfolder\n",
    "model_ID = \"\"\n",
    "DATA_PATH = os.path.join(INFERENCE_FOLDER_PATH,\"data\")\n",
    "DATA_PATH_RAW = os.path.join(DATA_PATH,\"raw\")\n",
    "TEMP_PATH = os.path.join(INFERENCE_FOLDER_PATH,\"temp\")\n",
    "os.makedirs(TEMP_PATH,exist_ok=True)\n",
    "MODEL_PATH = os.path.join(INFERENCE_FOLDER_PATH,\"utils\")\n",
    "# Specify the Model ID\n",
    "SAVE_ROOT = os.path.join(INFERENCE_FOLDER_PATH,\"out\")\n",
    "os.makedirs(TEMP_PATH,exist_ok=True)\n",
    "MODIFIED_DATA_PATH = os.path.join(TEMP_PATH,\"modified\")\n",
    "os.makedirs(MODIFIED_DATA_PATH,exist_ok=True)\n",
    "SPLIT_DATA_PATH = os.path.join(TEMP_PATH,\"split\")\n",
    "os.makedirs(SPLIT_DATA_PATH,exist_ok=True)\n",
    "CONVERTER_PATH = os.path.join(INFERENCE_FOLDER_PATH,\"utils\")\n",
    "SPEC_SAVE_ROOT = os.path.join(SAVE_ROOT, model_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:52:18.572288Z",
     "start_time": "2020-06-07T13:49:19.369623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Thesis\\inference_folder\\data\\raw\n",
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2514b45835904b0fbd97623577e9adc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Modify the raw data\n",
    "Modify.full_auto(DATA_PATH, MODIFIED_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T14:22:51.775225Z",
     "start_time": "2020-06-07T14:22:39.846873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint and Faulty found, skipping them, starting at:  LoadCase_7813.npy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9f82958a10453f991a5f63c775f4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Split and pad it\n",
    "Split.full_auto_split(MODIFIED_DATA_PATH,SPLIT_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:52:46.381266Z",
     "start_time": "2020-06-07T13:52:23.485950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the Model\n",
    "tf.keras.backend.clear_session()\n",
    "model = load_model(model_ID,MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T14:23:22.899954Z",
     "start_time": "2020-06-07T14:23:19.414525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/Thesis/inference_folder/temp\\split\\raw\n",
      "LoadCase_7813\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\Thesis\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Eine Datei kann nicht erstellt werden, wenn sie bereits vorhanden ist: 'F:/Thesis/inference_folder/out\\\\ID_309\\\\LoadCase_7813'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e3978be031ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     Outtxt.create_prediction_txt(model,DATA_PATH_RAW,s, model_ID\n\u001b[1;32m----> 7\u001b[1;33m                           ,SPEC_SAVE_ROOT,CONVERTER_PATH)\n\u001b[0m",
      "\u001b[1;32mD:\\Python Projects\\Bachelor Thesis\\2020\\untettop_git\\inference\\create_output_txt.ipynb\u001b[0m in \u001b[0;36mcreate_prediction_txt\u001b[1;34m(model, DATA_PATH_RAW, SPLIT_DATA_PATH, model_id, SAVE_ROOT, converter_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m    },\n\u001b[0;32m     12\u001b[0m    \u001b[1;34m\"outputs\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m    \"source\": [\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;34m\"# Necessary Imports\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;34m\"from tqdm import tqdm_notebook\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Thesis\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create the output folders\n",
    "MODIFIED_DATA_PATH_temp, SPLIT_DATA_PATH_temp = Modify.loadcase_folder_paths(MODIFIED_DATA_PATH,SPLIT_DATA_PATH)\n",
    "\n",
    "for i , s in enumerate(SPLIT_DATA_PATH_temp):\n",
    "    print(s)\n",
    "    Outtxt.create_prediction_txt(model,DATA_PATH_RAW,s, model_ID\n",
    "                          ,SPEC_SAVE_ROOT,CONVERTER_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
